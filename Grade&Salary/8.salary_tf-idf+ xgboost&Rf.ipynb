{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32708da-aa07-4ceb-9ccc-7fadedbc8a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.10/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install seaborn\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f57e69-a737-4cab-92ef-63382c4b65ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 235277\n",
      "Number of columns: 60\n"
     ]
    }
   ],
   "source": [
    "output=pd.read_csv('data_with_internal_info.csv', low_memory=False)\n",
    "rows, columns = output.shape\n",
    "print(\"Number of rows:\", rows)\n",
    "print(\"Number of columns:\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db033a9-c787-4e8f-bea3-7c4514ca14bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /opt/conda/lib/python3.10/site-packages (from xgboost) (2.27.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.15.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c66658-7bef-432b-9556-1a7b752df7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluation for Salary prediction(TF-IDF + SVD + XGBoost)\n",
      "MAE:  1983.0597\n",
      "RMSE: 6832.0659\n",
      "R²:   0.0815\n",
      "MAPE: 0.0301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "_stopwords = set(stopwords.words(\"english\"))\n",
    "_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_prep(text_list):\n",
    "    cleaned = []\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for doc in text_list:\n",
    "        doc = str(doc).lower().translate(table)\n",
    "        doc = doc.replace('\\n', ' ')\n",
    "        doc = re.sub(r'[^a-z0-9._\\s]', '', doc)\n",
    "        doc = re.sub(r'\\s+', ' ', doc).strip()\n",
    "        tokens = [tok for tok in doc.split() if tok not in _stopwords and len(tok) > 2]\n",
    "        lemmas = [_lemmatizer.lemmatize(tok) for tok in tokens]\n",
    "        cleaned.append(\" \".join(lemmas))\n",
    "    return cleaned\n",
    "columns_to_combine = [\n",
    "    'Job Title (en)', 'Job Title (nl)', 'Domain (en)', 'Specialisation (en)', 'Career ladder en',\n",
    "    'Level Title', 'Function goal', 'Key result areas: result area (1)', 'Key result areas: result area (2)',\n",
    "    'Key result areas: result area (3)', 'Key result areas: result area (4)', 'Key result areas: result area (5)',\n",
    "    'Key result areas: result area (6)', 'Key result areas: result area (7)', 'Key result areas: result area (8)',\n",
    "    'Key result areas: result area (9)', 'Key result areas: result area (10)', 'Key result areas: result area (11)',\n",
    "    'Key result areas: result area (12)', 'Key result areas: result area (13)', 'Key result areas: result area (14)',\n",
    "    'Key result areas: result area (15)', 'HIERARCHIC MANAGEMENT', 'FUNCTIONAL MANAGEMENT',\n",
    "    'Leadership | Manage the following job(s)', 'Managed by',\n",
    "    'Is he/ she responsible for a certain budget/ figure?', 'Specify the budget amounts.', 'Diploma',\n",
    "    'Speciality', 'Required experience', 'Innovation', 'Distinguishing factors | Row 1 - Column 1',\n",
    "    'Row 2 - Column 1', 'Row 3 - Column 1', 'Row 4 - Column 1', 'Row 5 - Column 1', 'Row 6 - Column 1',\n",
    "    'Row 7 - Column 1', 'Row 8 - Column 1', 'Row 9 - Column 1', 'Compas Grade', 'Reference Job', 'Age',\n",
    "     'Number of employees in Belgium', 'Job Grade Reference Job', 'Diploma Category',\n",
    "    'Job Level', 'Internal Job', 'Internal Job Grade', 'Department'\n",
    "]\n",
    "output[columns_to_combine] = output[columns_to_combine].astype(str)\n",
    "output['Yearly Gross Base Salary'] = pd.to_numeric(output['Yearly Gross Base Salary'], errors='coerce')\n",
    "\n",
    "text_combined = output[columns_to_combine].agg(' '.join, axis=1).tolist()\n",
    "text_cleaned = text_prep(text_combined)\n",
    "\n",
    "# Text pipeline: TF-IDF + SVD\n",
    "text_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        max_features=2000,\n",
    "        sublinear_tf=True,\n",
    "        smooth_idf=True,\n",
    "        stop_words='english',\n",
    "        tokenizer=lambda x: x.split(),\n",
    "        preprocessor=lambda x: x\n",
    "    )),\n",
    "    ('svd', TruncatedSVD(n_components=100, random_state=11))\n",
    "])\n",
    "\n",
    "X_text = text_pipe.fit_transform(text_cleaned)\n",
    "X_text = pd.DataFrame(X_text, index=output.index)\n",
    "X = X_text\n",
    "\n",
    "y = output['Yearly Gross Base Salary'].fillna(output['Yearly Gross Base Salary'].mean())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=11\n",
    ")\n",
    "\n",
    "# XGBoost regressor\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=11\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\" Evaluation for Salary prediction(TF-IDF + SVD + XGBoost)\")\n",
    "print(f\"MAE:  {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred) ** 0.5:.4f}\")\n",
    "print(f\"R²:   {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_test, y_pred):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fdddd2-7a34-4651-b7a1-17135f46f427",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.6; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.6; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.6; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.6; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.6; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.6; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.6; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.6; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.6; total time=   6.8s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.6; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.6; total time=   2.8s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.6; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.6; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.6; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.6; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.6; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.6; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.6; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "Best hyperparameters for XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.6}\n",
      "\n",
      "--- Evaluation for Salary prediction with XGBoost (tuned) ---\n",
      "  MAE:  1619.2431774181396\n",
      "  RMSE: 6965.410288109124\n",
      "  R²:   0.045307634426625776\n",
      "  MAPE: 0.024972589918596383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import xgboost as xgb\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',             \n",
    "    verbosity=1,\n",
    "    random_state=11)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.6, 1.0]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    model_xgb,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=1,\n",
    "    verbose=2\n",
    "    \n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters for XGBoost:\", grid_search.best_params_)\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_true = y_test.values.flatten()\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Evaluation for Salary prediction with XGBoost (tuned) ---\")\n",
    "print(\"  MAE: \", mean_absolute_error(y_true, y_pred))\n",
    "print(\"  RMSE:\", mean_squared_error(y_true, y_pred)**0.5)\n",
    "print(\"  R²:  \", r2_score(y_true, y_pred))\n",
    "print(\"  MAPE:\", mean_absolute_percentage_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3f5f9c-ad19-4c89-b1dd-bb12ab12bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation for SALARY prediction (Random Forest regressors with TF-IDF)\n",
      "  MAE: 1868.710950102236\n",
      "  RMSE: 6880.342796378206\n",
      "  R²: 0.06848426260917484\n",
      "  MAPE: 0.02849770239952594\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=11,\n",
    "    n_jobs=-1\n",
    ")\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test .columns = X_test .columns.astype(str)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n Evaluation for SALARY prediction (Random Forest regressors with TF-IDF)\")\n",
    "print(\"  MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"  RMSE:\", mean_squared_error(y_test, y_pred_rf) ** 0.5)\n",
    "print(\"  R²:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"  MAPE:\", mean_absolute_percentage_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97acb96a-2102-4be4-8739-4dcb8847eb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best hyperparameters for RandomForest: {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Evaluation for Salary prediction (Random Forest with GridSearch)\n",
      "  MAE:  1688.6755485620752\n",
      "  RMSE: 6905.437623596581\n",
      "  R²:   0.061676794583432115\n",
      "  MAPE: 0.025944877729786407\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning RF with GridSearchCV\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth':    [ 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf':  [1, 2],\n",
    "    'max_features': ['log2', 'sqrt']}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2)\n",
    "\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "print(\"Best hyperparameters for RandomForest:\", grid_search_rf.best_params_)\n",
    "\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nEvaluation for Salary prediction (Random Forest with GridSearch)\")\n",
    "print(\"  MAE: \", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"  RMSE:\", mean_squared_error(y_test, y_pred_rf) ** 0.5)\n",
    "print(\"  R²:  \", r2_score(y_test, y_pred_rf))\n",
    "print(\"  MAPE:\", mean_absolute_percentage_error(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
