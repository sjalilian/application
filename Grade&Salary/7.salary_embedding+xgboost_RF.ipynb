{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c11fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.55.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (0.34.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f57e69-a737-4cab-92ef-63382c4b65ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazan\\AppData\\Local\\Temp\\ipykernel_33532\\331495582.py:2: DtypeWarning: Columns (12,13,14,15,16,17,24,29,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  output=pd.read_csv('data_with_internal_info.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 235277\n",
      "Number of columns: 60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output=pd.read_csv('data_with_internal_info.csv')\n",
    "rows, columns = output.shape\n",
    "print(\"Number of rows:\", rows)\n",
    "print(\"Number of columns:\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a669682e-2f77-4a78-b4c3-ac8e374aede8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nazan\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nazan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nazan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Batches: 100%|██████████| 7353/7353 [1:19:21<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Salary Prediction ---\n",
      "MAE: 1870.5103037935796\n",
      "RMSE: 6904.304761217076\n",
      "R2: 0.06198464005923776\n",
      "MAPE: 0.028626305816052838\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "_stopwords = set(stopwords.words(\"english\"))\n",
    "_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_prep(text_list):\n",
    "    cleaned = []\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for doc in text_list:\n",
    "        doc = str(doc).lower().translate(table)\n",
    "        doc = doc.replace('\\n', ' ')\n",
    "        doc = re.sub(r'[^a-z0-9._\\s]', '', doc)\n",
    "        doc = re.sub(r'\\s+', ' ', doc).strip()\n",
    "        tokens = [tok for tok in doc.split() if tok not in _stopwords and len(tok) > 2]\n",
    "        lemmas = [_lemmatizer.lemmatize(tok) for tok in tokens]\n",
    "        cleaned.append(\" \".join(lemmas))\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "columns_to_combine = [\n",
    "    'Job Title (en)', 'Job Title (nl)', 'Level Title', 'Function goal', \n",
    "    'Key result areas: result area (1)', 'Key result areas: result area (2)',\n",
    "    'Key result areas: result area (3)', 'Key result areas: result area (4)',\n",
    "    'Key result areas: result area (5)', 'Key result areas: result area (6)',\n",
    "    'Key result areas: result area (7)', 'Key result areas: result area (8)',\n",
    "    'Key result areas: result area (9)', 'Key result areas: result area (10)',\n",
    "    'Key result areas: result area (11)', 'Specify the budget amounts.', \n",
    "    'Diploma Category', 'Speciality', 'Required experience', 'Innovation', \n",
    "    'Row 4 - Column 1', 'Row 5 - Column 1',\n",
    "    'Row 6 - Column 1', 'Row 7 - Column 1', 'Row 8 - Column 1',\n",
    "    'Internal Job', 'Internal Job Grade', 'Department'\n",
    "]\n",
    "\n",
    "output[columns_to_combine] = output[columns_to_combine].astype(str)\n",
    "output['Yearly Gross Base Salary'] = pd.to_numeric(output['Yearly Gross Base Salary'], errors='coerce')\n",
    "\n",
    "\n",
    "text_combined = output[columns_to_combine].agg(' '.join, axis=1).tolist()\n",
    "text_cleaned = text_prep(text_combined)\n",
    "\n",
    "\n",
    "embedder = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "X = embedder.encode(text_cleaned, show_progress_bar=True)\n",
    "X = pd.DataFrame(X, index=output.index)\n",
    "\n",
    "y = output['Yearly Gross Base Salary'].fillna(output['Yearly Gross Base Salary'].mean())\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=11,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"--- Salary Prediction ---\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff9b4e2-246b-4931-aab6-128c5fd66e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best hyperparameters for RandomForest: {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      " Evaluation for Salary prediction (Random Forest with GridSearch) \n",
      "  MAE:  1735.0538317470498\n",
      "  RMSE: 6931.8861685492775\n",
      "  R²:   0.05447527855402068\n",
      "  MAPE: 0.026693830858119365\n"
     ]
    }
   ],
   "source": [
    "#Random Forest fine-tuning with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth':    [ 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf':  [1, 2],\n",
    "    'max_features': ['log2', 'sqrt']\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2)\n",
    "\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "print(\"Best hyperparameters for RandomForest:\", grid_search_rf.best_params_)\n",
    "\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\n Evaluation for Salary prediction (Random Forest with GridSearch) \")\n",
    "print(\"  MAE: \", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"  RMSE:\", mean_squared_error(y_test, y_pred_rf) ** 0.5)\n",
    "print(\"  R²:  \", r2_score(y_test, y_pred_rf))\n",
    "print(\"  MAPE:\", mean_absolute_percentage_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b96d473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (3.0.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.15.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7220f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nazan\\appdata\\roaming\\python\\python312\\site-packages (3.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\nazan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.15.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5dafcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation for Salary prediction (XGBoost with Embeddings(base model)) ---\n",
      "  MAE: 1993.1919064757512\n",
      "  RMSE: 6883.414163460658\n",
      "  R²: 0.0676524245933251\n",
      "  MAPE: 0.03036814999341633\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=11\n",
    ")\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n--- Evaluation for Salary prediction (XGBoost with Embeddings(base model)) ---\")\n",
    "print(\"  MAE:\", mean_absolute_error(y_test, y_pred_xgb))\n",
    "print(\"  RMSE:\", mean_squared_error(y_test, y_pred_xgb) ** 0.5)\n",
    "print(\"  R²:\", r2_score(y_test, y_pred_xgb))\n",
    "print(\"  MAPE:\", mean_absolute_percentage_error(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c8bb47-fb35-4f82-b1fc-94874eb1e634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.6; total time=   9.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.6; total time=   9.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.6; total time=   8.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   8.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   9.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   9.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6; total time=  18.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6; total time=  18.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6; total time=  18.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  19.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  20.3s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  19.9s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.6; total time=  24.6s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.6; total time=  18.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.6; total time=  19.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=  21.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=  21.5s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=  21.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.6; total time=  38.4s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.6; total time=  39.5s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.6; total time=  37.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=  43.8s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=  43.1s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=  43.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=  12.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=  12.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=  12.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=  15.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=  15.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=  15.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.6; total time=  28.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.6; total time=  27.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.6; total time=  28.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  27.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  27.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  26.3s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.6; total time=  19.9s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.6; total time=  20.0s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.6; total time=  16.9s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=  20.8s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=  21.1s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=  22.1s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.6; total time=  36.5s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.6; total time=  37.0s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.6; total time=  37.0s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=  43.2s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=  39.3s\n",
      "[CV] END learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=  33.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.6; total time=  11.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.6; total time=  11.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.6; total time=  11.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=  12.3s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=  12.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.6; total time=  21.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.6; total time=  21.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.6; total time=  30.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  29.3s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  25.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  22.1s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.6; total time=  17.3s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.6; total time=  17.3s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.6; total time=  17.8s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=  19.4s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=  18.9s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=  17.8s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.6; total time=  32.5s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.6; total time=  33.8s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.6; total time=  36.5s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=  42.8s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=  39.7s\n",
      "[CV] END learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=  33.9s\n",
      "Best hyperparameters for XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.6}\n",
      "\n",
      "Evaluation for Salary with XGBoost (tuned model)\n",
      "  MAE:  1598.340592477995\n",
      "  RMSE: 6978.471115267325\n",
      "  R²:   0.041723994174017176\n",
      "  MAPE: 0.024701614569525028\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning XGBoost with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.6, 1.0]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    model_xgb,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=1,\n",
    "    verbose=2\n",
    "    \n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters for XGBoost:\", grid_search.best_params_)\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_true = y_test.values.flatten()\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\nEvaluation for Salary with XGBoost (tuned model)\")\n",
    "print(\"  MAE: \", mean_absolute_error(y_true, y_pred))\n",
    "print(\"  RMSE:\", mean_squared_error(y_true, y_pred)**0.5)\n",
    "print(\"  R²:  \", r2_score(y_true, y_pred))\n",
    "print(\"  MAPE:\", mean_absolute_percentage_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf9f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "save_dir = \"models/salary\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save XGBoost model\n",
    "best_xgb.save_model(f\"{save_dir}/salary_xgboost.json\")\n",
    "\n",
    "# 2. Save the SentenceTransformer embedder\n",
    "embedder.save(f\"{save_dir}/embedding_model\")\n",
    "\n",
    "# 3. Save metadata (columns list)\n",
    "joblib.dump(columns_to_combine, f\"{save_dir}/columns_to_combine.pkl\")\n",
    "\n",
    "print(\"Salary model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061ecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
