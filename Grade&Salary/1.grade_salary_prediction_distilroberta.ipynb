{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5c8ced-f240-4217-86bd-bcbbeb724b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('data_with_internal_info.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e31e40-a9cd-4642-94ca-e40217dae436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "def text_prep(text):\n",
    "    text = [str(t).lower() for t in text]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    text = [t.translate(table) for t in text]\n",
    "    # text = [re.sub(r'\\d+', 'num', t) for t in text]\n",
    "    text = [t.replace('\\n', ' ') for t in text]\n",
    "    text = [re.sub(r'[^a-zA-Z0-9._\\s]', '', t) for t in text]\n",
    "    text = [re.sub(r'\\s+', ' ', t).strip() for t in text]\n",
    "    return text\n",
    "\n",
    "columns_to_combine = [\n",
    "    'Job Title (en)', 'Job Title (nl)', 'Level Title', 'Function goal', \n",
    "    'Key result areas: result area (1)', 'Key result areas: result area (2)',\n",
    "    'Key result areas: result area (3)', 'Key result areas: result area (4)',\n",
    "    'Key result areas: result area (5)', 'Key result areas: result area (6)',\n",
    "    'Key result areas: result area (7)', 'Key result areas: result area (8)',\n",
    "    'Key result areas: result area (9)', 'Key result areas: result area (10)',\n",
    "    'Key result areas: result area (11)', 'Specify the budget amounts.', \n",
    "    'Diploma Category', 'Speciality', 'Required experience', 'Innovation', \n",
    "    'Row 4 - Column 1', 'Row 5 - Column 1',\n",
    "    'Row 6 - Column 1', 'Row 7 - Column 1', 'Row 8 - Column 1','Internal Job', 'Internal Job Grade', 'Department'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34233780-e3df-46f6-aa81-3a2b2c869903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_salary.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "data['Yearly Gross Base Salary'] = (\n",
    "    data['Yearly Gross Base Salary']\n",
    "        .astype(str)\n",
    "        .str.replace(',', '.', regex=False))\n",
    "data['Yearly Gross Base Salary'] = pd.to_numeric(\n",
    "    data['Yearly Gross Base Salary'],\n",
    "    errors='coerce')\n",
    "data['Yearly Gross Base Salary'].fillna(\n",
    "    data['Yearly Gross Base Salary'].mean())\n",
    "\n",
    "data = data.dropna(subset=['Compas Grade', 'Yearly Gross Base Salary'])\n",
    "\n",
    "y_grade  = data['Compas Grade'].astype(float).values.reshape(-1, 1)\n",
    "y_salary = data['Yearly Gross Base Salary'].values.reshape(-1, 1)\n",
    "\n",
    "scaler_salary   = StandardScaler()\n",
    "y_salary_scaled = scaler_salary.fit_transform(y_salary)\n",
    "\n",
    "y = np.hstack([y_grade, y_salary_scaled])\n",
    "\n",
    "data[columns_to_combine] = data[columns_to_combine].astype(str)\n",
    "text_combined           = data[columns_to_combine].agg(' '.join, axis=1).tolist()\n",
    "text_cleaned            = text_prep(text_combined)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "toks = tokenizer(\n",
    "    text_cleaned,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=16,\n",
    "    return_tensors='np'\n",
    ")\n",
    "\n",
    "input_ids = toks[\"input_ids\"]\n",
    "attention_mask = toks[\"attention_mask\"]\n",
    "\n",
    "np.savez(\n",
    "    \"tokenized_data.npz\",\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    labels=y)\n",
    "joblib.dump(scaler_salary, \"scaler_salary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478cf49f-bcb4-41e2-ad7e-086dfc7d69d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 19:24:49.057278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762543489.079979  262681 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762543489.088267  262681 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762543489.110125  262681 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762543489.110156  262681 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762543489.110158  262681 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762543489.110161  262681 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-07 19:24:49.116543: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Epoch 1 Training: 100%|██████████| 2941/2941 [24:47<00:00,  1.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 1.2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 2941/2941 [27:22<00:00,  1.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.4737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 2941/2941 [27:25<00:00,  1.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.4569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 736/736 [01:39<00:00,  7.36batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Compas Grade ===\n",
      "MAE:  0.521529495716095\n",
      "RMSE: 0.6564356677485514\n",
      "R2:   0.9488176703453064\n",
      "MAPE: 0.05226004123687744\n",
      "\n",
      "=== Yearly Salary (EUR) ===\n",
      "MAE:  11539.0478515625\n",
      "RMSE: 15679.535707411747\n",
      "R2:   0.5710670351982117\n",
      "MAPE: 0.18734505772590637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "arr = np.load(\"tokenized_data.npz\")\n",
    "input_ids      = arr['input_ids']\n",
    "attention_mask = arr['attention_mask']\n",
    "labels_all     = arr['labels']           \n",
    "scaler_salary  = joblib.load(\"scaler_salary.pkl\")\n",
    "\n",
    "\n",
    "grades = labels_all[:,0].astype(int)\n",
    "X_ids_train, X_ids_test, X_mask_train, X_mask_test, \\\n",
    "y_train,     y_test = train_test_split(\n",
    "    input_ids,\n",
    "    attention_mask,\n",
    "    labels_all,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=grades\n",
    ")\n",
    "\n",
    "class JobDataset(Dataset):\n",
    "    def __init__(self, ids, masks, labels):\n",
    "        self.ids    = ids\n",
    "        self.masks  = masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids':      torch.tensor(self.ids[idx],   dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.masks[idx], dtype=torch.long),\n",
    "            'labels':         torch.tensor(self.labels[idx],dtype=torch.float)\n",
    "        }\n",
    "\n",
    "train_ds = JobDataset(X_ids_train, X_mask_train, y_train)\n",
    "test_ds  = JobDataset(X_ids_test,  X_mask_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "bert_back  = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "class BertRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert      = bert_back\n",
    "        self.dropout   = nn.Dropout(0.2)\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out  = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls  = out.last_hidden_state[:,0,:]\n",
    "        x    = self.dropout(cls)\n",
    "        return self.regressor(x) \n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model  = BertRegressor().to(device)  \n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn   = nn.MSELoss()\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "   \n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", unit=\"batch\"):\n",
    "        ids   = batch['input_ids'].to(device)\n",
    "        mask  = batch['attention_mask'].to(device)\n",
    "        labs  = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(ids, mask)\n",
    "        loss  = loss_fn(preds, labs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} — Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_true = [], []\n",
    "for batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "    with torch.no_grad():\n",
    "        ids  = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labs = batch['labels'].cpu().numpy()\n",
    "\n",
    "        out  = model(ids, mask).cpu().numpy()\n",
    "        all_true.append(labs)\n",
    "        all_preds.append(out)\n",
    "\n",
    "all_true  = np.vstack(all_true)\n",
    "all_preds = np.vstack(all_preds)\n",
    "\n",
    "grade_true, salary_true_s = all_true[:,0], all_true[:,1]\n",
    "grade_pred, salary_pred_s = all_preds[:,0], all_preds[:,1]\n",
    "\n",
    "salary_true = scaler_salary.inverse_transform(salary_true_s.reshape(-1,1)).ravel()\n",
    "salary_pred = scaler_salary.inverse_transform(salary_pred_s.reshape(-1,1)).ravel()\n",
    "\n",
    "def print_metrics(y_t, y_p, name):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"MAE: \", mean_absolute_error(y_t, y_p))\n",
    "    print(\"RMSE:\", mean_squared_error(y_t, y_p)** 0.5)\n",
    "    print(\"R2:  \", r2_score(y_t, y_p))\n",
    "    print(\"MAPE:\", mean_absolute_percentage_error(y_t, y_p))\n",
    "print_metrics(grade_true,  grade_pred,  \"Compas Grade\")\n",
    "print_metrics(salary_true, salary_pred, \"Yearly Salary (EUR)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424f50bd-4a9c-4943-abcd-6d583bf80019",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_job_description=\"\"\" \n",
    "Working at Randstad is unlike working at any organization. Because at Randstad we put people at the heart of everything we do. This goes for our clients, our talent, our employees and society. We combine our passion for people with the power of today’s technologies. This helps us support people and organizations in realizing their true potential. Learn more about our mission, history and values on our website: www.randstad.com\n",
    "how you will contribute :\n",
    "\n",
    "As a Machine Learning Engineer / Data Scientist you will create brand new insights into the global world of work. We use the latest ML and AI techniques to deliver highly accurate models for supporting a variety of business applications and processes, including market demand, talent supply, career patterns, salaries and rates, and pricing.\n",
    "\n",
    "The focus in this role will be working on our global taxonomy program, that is supporting our systems landscape worldwide. In this program we are creating and maintaining information on all kinds of vital elementary data concepts, such as jobs, occupations, skills, certificates, education and more. We are using the latest ML technology and LLMs to create our models, and present the results via ML pipelines with a balanced set of microservices.\n",
    "\n",
    "You will be a part of an international and agile team of highly skilled specialists, including data scientists, ML engineers, data engineers, and data analysts. We have a major research background and are publishing some of our greatest work in academic papers.\n",
    "\n",
    "You will work closely with other colleagues within the Randstad ecosystem, especially in the various global projects. The impact of your work depends not only on the quality of your products, but especially on your ability to communicate the value and proof of concept of your models and analyses.\n",
    "\n",
    "what you will be doing \n",
    "\n",
    "building Machine Learning (ML) models: preparing data from a wide variety of internal and external data sources; creating and evaluating ML models, primarily in the NLP domain, based a.o. on open source LLMs and GenAI; \n",
    "\n",
    "● building ML pipelines that automate the training and deployment of models\n",
    "\n",
    "● defining and appropriating work to the product backlog\n",
    "\n",
    "● training and coaching junior team members\n",
    "\n",
    "● collaborating within the data science community within the Randstad ecosystem, on sharing best practices, harmonizing ML models, and grow collective data science skills\n",
    "who will you work with \n",
    "\n",
    "Our global data science team helps our customers make better hiring decisions and helps talent advance in their career paths. We help people find work by creating new insights into the dynamics of the global labor market and integrate those insights into customer- and talent-focused data products. We build and deploy machine learning models and tell stories with those insights. As an example - we create clarity where there are gaps in diversity, what a talent's next job might be, how market conditions should influence a hiring strategy, where we predict demand will go, and much more.\n",
    "\n",
    "what you will bring \n",
    "\n",
    "● Masters degree in Computer science / Data Science, or related technical studies (M.Sc. or equivalent experience)\n",
    "● min. 2 to 3 years work experience as a ML engineer or data scientist with strong engineering skills\n",
    "● machine learning (ML) platform: excellent working knowledge of analytical, AI and ML stacks on cloud platforms, preferably on Google Cloud Platform (incl. BigQuery, AI & ML stack) or comparable platforms\n",
    "● coding: high proficiency in Python (incl. relevant libraries and packages) and SQL\n",
    "● ML engineering: experience with the creation of ML pipelines and ML Ops related techniques\n",
    "● ML modeling: relevant experience with NLP, LLMs, and working with the set of tools needed to build models on large and complex datasets (preferably in applied and research setting)\n",
    "\n",
    "what’s in it for you \n",
    "\n",
    "We put people at the heart of everything we do. Our employment conditions reflect this;\n",
    "\n",
    "● competitive salary\n",
    "● an additional flexible benefit budget\n",
    "● attractive bonus scheme\n",
    "● option to take part in Randstad's success through our employee Share Purchase Plan\n",
    "● option to go on a sabbatical leave or buy extra holidays\n",
    "● flexible working hours in the office or hybrid]\n",
    "● attractive mobility arrangements\n",
    "● opportunity to give back to local communities through paid volunteering leave\n",
    "● a generous budget to set up your home office space and a net internet allowance]\n",
    "\n",
    "● growth and development opportunities in a fast changing global environment\n",
    "\n",
    "● working with great people and being part of a network where everyone wants you to succeed\n",
    "\n",
    "● an environment where differences are understood, valued and celebrated\n",
    "\n",
    "We want our teams and talent to reflect the rich diversity of the societies we serve. We thrive for an environment of belonging, safety and confidence. So everyone can bring their whole selves to work and flourish. Learn more about equity, diversity, inclusion and belonging at randstad here.\n",
    "\n",
    "If you recognize yourself in the profile above, we invite you to apply for this role.\n",
    "\n",
    "For more information you can reach out to our recruitment business partner Jenny Roberts .\n",
    "\n",
    "The recruitment procedure consists of a screening and at least two interviews. Later in the process, an (online) assessment and a job offer conversation take place\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fbef94-0c19-4eba-a997-3f286d20bf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction ===\n",
      "Estimated Compas Grade: 10.67\n",
      "Estimated Salary (EUR): 61734\n"
     ]
    }
   ],
   "source": [
    "# 1) Preprocess\n",
    "clean_text = text_prep([sample_job_description])\n",
    "\n",
    "# 2) Tokenize\n",
    "tok = tokenizer(\n",
    "    clean_text,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=16,   # must match training\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "ids  = tok.input_ids.to(device)\n",
    "mask = tok.attention_mask.to(device)\n",
    "\n",
    "# 3) Predict with BERT regressor\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(ids, mask).cpu().numpy()[0]\n",
    "\n",
    "# Outputs: [grade, salary_scaled]\n",
    "grade_pred  = pred[0]\n",
    "salary_pred_s = pred[1]\n",
    "\n",
    "# 4) Convert salary back\n",
    "salary_pred = scaler_salary.inverse_transform([[salary_pred_s]])[0][0]\n",
    "\n",
    "print(\"\\n=== Prediction ===\")\n",
    "print(\"Estimated Compas Grade:\", round(grade_pred, 2))\n",
    "print(\"Estimated Salary (EUR):\", int(salary_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851b568-8e20-4f84-a5cc-910831e275a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, datetime as dt\n",
    "\n",
    "salary_eur   = int(salary_pred)\n",
    "compas_grade = float(round(grade_pred, 2))\n",
    "\n",
    "def ask_and_save(salary, grade, job_desc, out_path=\"outputs/prediction_feedback.csv\"):\n",
    "    while True:\n",
    "        try:\n",
    "            resp = input(\"Do you accept the result? [y/n]: \").strip().lower()\n",
    "        except EOFError:\n",
    "            print(\"No input available (non-interactive). Skipping save.\")\n",
    "            return\n",
    "        if resp in (\"y\", \"yes\", \"n\", \"no\"):\n",
    "            break\n",
    "        print(\"Please answer with y/yes or n/no.\")\n",
    "\n",
    "    if resp.startswith(\"n\"):\n",
    "        folder = os.path.dirname(out_path)\n",
    "        if folder:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        write_header = not os.path.exists(out_path)\n",
    "        with open(out_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=[\"timestamp\",\"salary_eur\",\"compas_grade\",\"job_description\"])\n",
    "            if write_header:\n",
    "                w.writeheader()\n",
    "            w.writerow({\n",
    "                \"timestamp\": dt.datetime.now().isoformat(timespec=\"seconds\"),\n",
    "                \"salary_eur\": salary,\n",
    "                \"compas_grade\": grade,\n",
    "                \"job_description\": job_desc\n",
    "            })\n",
    "        print(f\"Saved to {out_path}\")\n",
    "    else:\n",
    "        print(\"Not saved.\")\n",
    "\n",
    "ask_and_save(salary_eur, compas_grade, sample_job_description)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
